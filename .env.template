# n8n Architecture Firm Enrichment Pipeline - Environment Variables

# ===========================
# API Keys
# ===========================

# OpenAI (Required)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-xxx

# SerpAPI (Required for signal detection)
# Get from: https://serpapi.com/manage-api-key
SERPAPI_API_KEY=xxx

# Apollo.io (Required for contact discovery)
# Get from: https://app.apollo.io/#/settings/integrations/api
APOLLO_API_KEY=xxx

# BuiltWith (Optional - for tech stack detection)
# Get from: https://api.builtwith.com/
BUILTWITH_API_KEY=xxx

# Jina AI (Free alternative to Firecrawl for website scraping)
# No API key needed - uses free tier
# Docs: https://jina.ai/reader

# ===========================
# Database Configuration
# ===========================

# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=architecture_enrichment
POSTGRES_USER=postgres
POSTGRES_PASSWORD=yourpassword

# Connection string (alternative)
DATABASE_URL=postgresql://postgres:yourpassword@localhost:5432/architecture_enrichment

# ===========================
# n8n Configuration
# ===========================

# n8n Base URL
N8N_HOST=localhost
N8N_PORT=5678
N8N_PROTOCOL=http

# Queue Mode (for scaling to 10k+ firms)
# Uncomment and configure if using queue mode
# QUEUE_BULL_REDIS_HOST=localhost
# QUEUE_BULL_REDIS_PORT=6379
# QUEUE_BULL_REDIS_DB=0
# EXECUTIONS_MODE=queue

# Worker Configuration
# N8N_CONCURRENCY=10

# ===========================
# Output Configuration
# ===========================

# Google Sheets (Optional)
# Create a new Google Sheet and get the ID from the URL
# https://docs.google.com/spreadsheets/d/{GOOGLE_SHEET_ID}/edit
GOOGLE_SHEET_ID=your_sheet_id_here

# Slack Notifications (Optional)
# Channel for high-priority alerts
SLACK_CHANNEL=#sales-leads
SLACK_BOT_TOKEN=xoxb-your-token

# ===========================
# Pipeline Configuration
# ===========================

# CSV Input Path
# Path to your architecture firms CSV file
CSV_FILE_PATH=/path/to/your/architecture-firms.csv

# Batch Size
# Number of firms to process in parallel (adjust based on API rate limits)
BATCH_SIZE=10

# Enrichment Thresholds
# Minimum score to trigger medium enrichment
MEDIUM_ENRICHMENT_THRESHOLD=30
# Minimum score to trigger heavy enrichment (contact discovery)
HEAVY_ENRICHMENT_THRESHOLD=50

# Brief Generation Threshold
# Only generate briefs for firms with priority P1-P3
GENERATE_BRIEF_FOR_PRIORITIES=P1,P2,P3

# ===========================
# Cost Management
# ===========================

# OpenAI Model Selection
# Options: gpt-4o-mini, gpt-4o, gpt-4-turbo
# gpt-4o-mini is cheapest (~$0.15/1M input tokens)
LLM_MODEL_LIGHT=gpt-4o-mini
LLM_MODEL_HEAVY=gpt-4o-mini
LLM_MODEL_BRIEF=gpt-4o

# API Rate Limits (requests per minute)
SERPAPI_RATE_LIMIT=60
APOLLO_RATE_LIMIT=60
OPENAI_RATE_LIMIT=500

# Maximum LLM tokens per request
MAX_LLM_TOKENS=4096

# ===========================
# Feature Flags
# ===========================

# Enable/disable specific enrichment steps
ENABLE_SIGNAL_DETECTION=true
ENABLE_WEBSITE_SCRAPING=true
ENABLE_TECH_STACK_DETECTION=true
ENABLE_CONTACT_DISCOVERY=true
ENABLE_BRIEF_GENERATION=true

# Enable caching (requires Redis)
ENABLE_CACHING=false
REDIS_CACHE_TTL=604800  # 7 days in seconds

# ===========================
# Monitoring & Logging
# ===========================

# Log Level
# Options: error, warn, info, verbose, debug
LOG_LEVEL=info

# Enable Prometheus metrics (for production)
ENABLE_PROMETHEUS=false
PROMETHEUS_PORT=9090

# Sentry Error Tracking (optional)
# SENTRY_DSN=https://xxx@xxx.ingest.sentry.io/xxx

# ===========================
# Development Settings
# ===========================

# Set to 'true' to enable test mode (uses cached responses, doesn't make real API calls)
TEST_MODE=false

# Sample size for testing (process only first N firms)
TEST_SAMPLE_SIZE=10

# ===========================
# Security
# ===========================

# Encryption key for sensitive data storage
# Generate with: openssl rand -hex 32
ENCRYPTION_KEY=your_encryption_key_here

# Webhook secret (if using webhook triggers)
WEBHOOK_SECRET=your_webhook_secret_here

# ===========================
# Notes
# ===========================

# 1. Never commit this file with real API keys!
# 2. Copy to .env and fill in your actual values
# 3. Add .env to .gitignore
# 4. For n8n, you can also set these in Settings â†’ Variables or as Docker env vars
# 5. For production, use a secrets manager (e.g., AWS Secrets Manager, Vault)

# ===========================
# Quick Start
# ===========================

# 1. Copy this file: cp .env.template .env
# 2. Fill in your API keys above
# 3. Create the PostgreSQL database:
#    createdb architecture_enrichment
# 4. Run the schema:
#    psql -d architecture_enrichment -f database-schema.sql
# 5. Start n8n:
#    docker run -it --rm --name n8n -p 5678:5678 -v ~/.n8n:/home/node/.n8n n8nio/n8n
# 6. Import the workflow JSON in n8n
# 7. Add your CSV file path to CSV_FILE_PATH
# 8. Execute the workflow!
